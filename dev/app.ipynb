{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = {}\n",
    "conversation_history = []\n",
    "\n",
    "def update_memory(key, value):\n",
    "    memory[key] = value\n",
    "\n",
    "def get_memory(key):\n",
    "    return memory.get(key, None)\n",
    "\n",
    "def add_conversation(user_input, bot_response):\n",
    "    conversation_history.append({\"user\": user_input, \"bot\": bot_response})\n",
    "\n",
    "def get_conversation_history():\n",
    "    return conversation_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = 'salut'\n",
    "response = \"ok\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(add_conversation(user_input, response))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(update_memory('last_response', response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'user': 'salut', 'bot': 'ok'}, {'user': 'salut', 'bot': 'ok'}]\n"
     ]
    }
   ],
   "source": [
    "print(get_conversation_history())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = 'et toi alors'\n",
    "response = \"quoi ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_memory(user_input, bot_response):\n",
    "    conversation_history.append(f\"'user': {user_input}, 'bot': {bot_response}\")\n",
    "\n",
    "def get_memory():\n",
    "    return conversation_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_memory(user_input, response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'user': je suis seb, 'bot': comment ça va ?\",\n",
       " \"'user': et toi alors, 'bot': quoi ?\"]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_memory()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"\\'user\\': je suis seb, \\'bot\\': comment ça va ?\", \"\\'user\\': et toi alors, \\'bot\\': quoi ?\"]'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(conversation_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotMemory:\n",
    "    def __init__(self):\n",
    "        self.conversation_history = []\n",
    "\n",
    "    def update_memory(self, user_input, bot_response):\n",
    "        self.conversation_history.append(f\"'user': {user_input}, 'bot': {bot_response}\")\n",
    "\n",
    "    def get_memory(self):\n",
    "        return self.conversation_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'user': test, 'bot': test\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem = ChatbotMemory()\n",
    "mem.update_memory('test', 'test')\n",
    "mem.get_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Downloading ollama-0.2.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting httpx<0.28.0,>=0.27.0 (from ollama)\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting anyio (from httpx<0.28.0,>=0.27.0->ollama)\n",
      "  Downloading anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\stadiello\\appdata\\local\\miniconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.6.2)\n",
      "Collecting httpcore==1.* (from httpx<0.28.0,>=0.27.0->ollama)\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\stadiello\\appdata\\local\\miniconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.7)\n",
      "Collecting sniffio (from httpx<0.28.0,>=0.27.0->ollama)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Downloading ollama-0.2.1-py3-none-any.whl (9.7 kB)\n",
      "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "   ---------------------------------------- 0.0/75.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 75.6/75.6 kB 4.1 MB/s eta 0:00:00\n",
      "Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "   ---------------------------------------- 0.0/77.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 77.9/77.9 kB ? eta 0:00:00\n",
      "Downloading anyio-4.4.0-py3-none-any.whl (86 kB)\n",
      "   ---------------------------------------- 0.0/86.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 86.8/86.8 kB 5.1 MB/s eta 0:00:00\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 58.3/58.3 kB 3.2 MB/s eta 0:00:00\n",
      "Installing collected packages: sniffio, h11, httpcore, anyio, httpx, ollama\n",
      "Successfully installed anyio-4.4.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 ollama-0.2.1 sniffio-1.3.1\n"
     ]
    }
   ],
   "source": [
    "! pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from generateS import Generate\n",
    "mod = Generate(model='test')\n",
    "mod.model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.2.2-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Using cached numpy-2.0.0-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\stadiello\\appdata\\local\\miniconda3\\lib\\site-packages (from pandas) (2.9.0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\stadiello\\appdata\\local\\miniconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Using cached pandas-2.2.2-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "Downloading numpy-2.0.0-cp312-cp312-win_amd64.whl (16.2 MB)\n",
      "   ---------------------------------------- 0.0/16.2 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.3/16.2 MB 27.0 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 2.3/16.2 MB 24.0 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 3.3/16.2 MB 26.1 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 4.2/16.2 MB 22.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 5.6/16.2 MB 24.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 6.5/16.2 MB 24.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 7.4/16.2 MB 23.7 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 8.3/16.2 MB 24.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 9.1/16.2 MB 23.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 10.2/16.2 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 11.3/16.2 MB 22.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 12.2/16.2 MB 22.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 13.2/16.2 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.8/16.2 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.8/16.2 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  16.2/16.2 MB 23.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  16.2/16.2 MB 23.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 16.2/16.2 MB 18.2 MB/s eta 0:00:00\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.0.0 pandas-2.2.2 pytz-2024.1 tzdata-2024.1\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Titre</th>\n",
       "      <th>Conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, Titre, Conversation]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(columns=[\"Date\", \"Titre\", \"Conversation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "        \"Date\": ['1','2'],\n",
    "        \"Titre\": [\"title1\", \"title2\"],\n",
    "        \"user\": [\"conv1\", \"conv2\"],\n",
    "        \"bot\": [\"botconv1\", \"botconv2\"]\n",
    "    }\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Titre</th>\n",
       "      <th>user</th>\n",
       "      <th>bot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>title1</td>\n",
       "      <td>conv1</td>\n",
       "      <td>botconv1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>title2</td>\n",
       "      <td>conv2</td>\n",
       "      <td>botconv2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date   Titre   user       bot\n",
       "0    1  title1  conv1  botconv1\n",
       "1    2  title2  conv2  botconv2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Titre\"] != 'title1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Titre</th>\n",
       "      <th>user</th>\n",
       "      <th>bot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>title2</td>\n",
       "      <td>conv2</td>\n",
       "      <td>botconv2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date   Titre   user       bot\n",
       "1    2  title2  conv2  botconv2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst =  [\"'user': ceci est un petit test, 'bot':  Bonjour! Je suis là pour vous aider. Si vous avez des questions ou besoin d'assistance, n'hésitez pas à me les poser.\", \"'user': ok donne moi du code python, 'bot':  Bien sûr, je peux vous aider avec du code Python. N'hésitez pas à me faire une question spécifique ou un exemple de ce que vous voulez faire.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'user': ceci est un petit test, 'bot':  Bonjour! Je suis là pour vous aider. Si vous avez des questions ou besoin d'assistance, n'hésitez pas à me les poser.'user': ok donne moi du code python, 'bot':  Bien sûr, je peux vous aider avec du code Python. N'hésitez pas à me faire une question spécifique ou un exemple de ce que vous voulez faire.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = ''.join(lst)\n",
    "print(st)\n",
    "len(st.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compressed_memory(conv_hist:str)->str:    \n",
    "    summarizer = pipeline(\"summarization\")\n",
    "    summary = summarizer(conv_hist, max_length=150, min_length=30, do_sample=False)\n",
    "    return summary[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-keras\n",
      "  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tensorflow<2.17,>=2.16 in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from tf-keras) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.62.2)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow<2.17,>=2.16->tf-keras) (0.43.0)\n",
      "Requirement already satisfied: rich in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (13.7.1)\n",
      "Requirement already satisfied: namex in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (0.1.2)\n",
      "Downloading tf_keras-2.16.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tf-keras\n",
      "Successfully installed tf-keras-2.16.0\n"
     ]
    }
   ],
   "source": [
    "! pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google-t5/t5-small and revision d769bba (https://huggingface.co/google-t5/t5-small).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/Users/athena/Documents/projetGit/env4/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n",
      "Your max_length is set to 150, but your input_length is only 53. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=26)\n",
      "No model was supplied, defaulted to google-t5/t5-small and revision d769bba (https://huggingface.co/google-t5/t5-small).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n",
      "Your max_length is set to 150, but your input_length is only 60. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"ceci est un petit test, 'bot': Bonjour! Je suis là pour vous aider . n'hésitez pas à me les poser .\", \"'user': ok donne moi du code python, 'bot': Bien sûr, je peux vous aider avec du code Python .\"]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlst = [compressed_memory(el) for el in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(text: str) -> int:\n",
    "    normalized_text = ' '.join(text.split())\n",
    "    words = normalized_text.split()\n",
    "    return len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_summary_length(text_length: int) -> int:\n",
    "    \"\"\"\n",
    "    Determine the appropriate summary length based on the length of the input text.\n",
    "    \n",
    "    Parameters:\n",
    "    text_length (int): The length of the input text in terms of number of words.\n",
    "    \n",
    "    Returns:\n",
    "    int: The recommended number of words for the summary.\n",
    "    \n",
    "    Raises:\n",
    "    ValueError: If input is not a non-negative integer representing the word count of the text.\n",
    "    \"\"\"\n",
    "    if text_length < 0:\n",
    "        raise ValueError(\"Input must be a non-negative integer representing the word count of the text.\")\n",
    "    if text_length == 0:\n",
    "        return 0  # No words to summarize if the text length is 0.\n",
    "    summary_length = text_length  # Default to full length if no specific rules are applied.\n",
    "    if text_length > 50:\n",
    "        if text_length < 300:\n",
    "            summary_length = int(0.5 * text_length)  # 50% of original for short texts.\n",
    "        elif text_length < 1000:\n",
    "            summary_length = max(int(0.3 * text_length), 150)  # Scale down to 30% or 150 words, whichever is more.\n",
    "        else:\n",
    "            summary_length = max(int(0.1 * text_length), 300)  # Scale down to 10% or 300 words, whichever is more.\n",
    "    return summary_length\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent:str = 'salut je suis seb'\n",
    "txtLenght = count_words(sent)\n",
    "txtLenght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_summary_length(txtLenght)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
